run: # Configurations for a specific run
  random_seed: 12345 # Integer number of specifying random seed
  log_dir: demo_mia_gradients # String for indicating where to save all the information, including computed signals. 
  time_log: True # Indicate whether to log the time for each step

audit: # Configurations for auditing
  privacy_game: privacy_loss_model # Indicate the privacy game from privacy_loss_model, privacy_loss_sample
  report_log: report_gradients_normalized # String that indicates the folder where we save the and auditing report.
  offline: False # Indicate whether to use the offline setting (only out models) or the online settings (both in and out models)
  offline_a: 0.3 # parameter from which we compute p(x) from p_OUT(x) such that p(x) = 1/2 * ((a + 1) * p_OUT(x) + (1 - a))
  num_ref_models: 62 # number of reference models can be between 1 and 254. Beware of putting the right data_dir in data to select the right set of models. (below)
  augmentation: none # Indicate whether to use augmentation for the query points (if so, type "augmented")
  nb_augmentation: 0 # number of queries used for the attack (should have been computed beforehand). Can be 2 (original and mirrored), 18 (+shifts), 50...etc. 
  top_k: -1 # number of population z to use for the relative attack, can be -1 (all population is used) or anywhere between 1 and around 25K (depends on each dataset's size).
  signal: direct_gradients_normed # name of the signal used to perform the relative attack. Can be the used for other attacks. For relative attacks, 4 different signals: softmax_relative, taylor_softmax_relative, sm_softmax_relative, sm_taylor_softmax_relative (default)
  temperature: 2.0 # float: temperature applied to logits when computing signals
  gamma: 2.0 # float: gamma threshold for LRT(x,z,theta)
  target_idx: 0 # idx of the target model, can be int, "ten", "fifty", or "all" for an average over multiple models
  # subset: all # subset on which the attack is performed, can be "all", "typical", "atypical", "not typical", "not atypical"
  nb_models_per_gaussian: 16

data: # Configuration for input logits
  target_dir: scripts/exp/cifar10_64 # directory where the set of target models are trained (logits should have already been computed)
  reference_dir: scripts/exp/cifar10_64 # directory where the set of reference models are trained (can be identical to target_dir) (logits should have already been computed)
  dataset_size: 50000 # the size of the whole dataset for which we have computed the logits. (e.g. 50000, or 60000)
  epoch: 100 # epoch used for the models
