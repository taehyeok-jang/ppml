run: # Configurations for a specific run
  random_seed: 12345 # Integer number of specifying random seed
  log_dir: demo_mia_gradients # String for indicating where to save all the information, including computed signals. 
  time_log: True # Indicate whether to log the time for each step

audit: # Configurations for auditing
  privacy_game: privacy_loss_model # Indicate the privacy game from privacy_loss_model, privacy_loss_sample
  report_log: report_lira # String that indicates the folder where we save the and auditing report.
  offline: False # Indicate whether to use the offline setting (only out models) or the online settings (both in and out models)
  fix_variance: True
  num_ref_models: 32 # number of reference models can be between 1 and 254. Beware of putting the right data_dir in data to select the right set of models. (below)
  augmentation: none # Indicate whether to use augmentation for the query points (if so, type "augmented")
  nb_augmentation: 2 # number of queries used for the attack (should have been computed beforehand). Can be 2 (original and mirrored), 18 (+shifts), 50...etc. 
  signal: loss_logit_rescaled # name of the signal used to perform the relative attack. Can be the used for other attacks. For relative attacks, 4 different signals: softmax_relative, taylor_softmax_relative, sm_softmax_relative, sm_taylor_softmax_relative (default)
  target_idx: 0 # idx of the target model, can be int, "ten", "fifty", or "all" for an average over multiple models
  subset: 5k # subset on which the attack is performed, can be "all", "typical", "atypical", "not typical", "not atypical"

data: # Configuration for input logits
  target_dir: scripts/exp/cifar10_64 # directory where the set of target models are trained (logits should have already been computed)
  reference_dir: scripts/exp/cifar10_64 # directory where the set of reference models are trained (can be identical to target_dir) (logits should have already been computed)
  dataset_size: 50000 # the size of the whole dataset for which we have computed the logits. (e.g. 50000, or 60000)
  epoch: 100 # epoch used for the models
