{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee8fbd1-0da2-4f99-8472-ff6a76fcf907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime \n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import torch.utils.data as data # for code compatibility\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "import timm\n",
    "\n",
    "import scipy.stats\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# util\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# customized \n",
    "import models.arch as models\n",
    "\n",
    "import dataset.cifar100 as dataset\n",
    "# import dataset.cifar100_larger as dataset # for ViT model,\n",
    "\n",
    "from utils import Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from progress.bar import Bar as Bar\n",
    "import utils as utils_\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "##\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc020f14-3f82-4d5e-91b2-f631b4cb5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131e4c8-44de-48a2-8262-febbe8fabe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vgg19, CIFAR-100\n",
    "_arch = \"vgg19\"\n",
    "_dataset = \"cifar100\"\n",
    "\n",
    "_lr = 0.02\n",
    "_epochs = 50\n",
    "\n",
    "_debug = True\n",
    "_batch_size = 64\n",
    "\n",
    "_n_labeled = 10000\n",
    "# XXX TODO \n",
    "_n_unlabeled = 45000 - _n_labeled \n",
    "\n",
    "_alpha = 0.75\n",
    "_lambda_u = 20 # default: 75\n",
    "\n",
    "_ema_decay = 0.999 # default: 0.999\n",
    "_T = 0.5 # default: 0.5\n",
    "# XXX TODO \n",
    "_train_iteration = int(max(_n_labeled, _n_unlabeled) / _batch_size) # phase 1: support full-supervised learning, default: 1024\n",
    "# _train_iteration = int(_n_labeled / _batch_size) # phase 1: support full-supervised learning, default: 1024\n",
    "\n",
    "# XXX TODO \n",
    "_n_classes = 100 # depend on dataset\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7019f1-f206-43c4-bb26-556167d635e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments/vgg19_only/cifar100@10000_lu_20_iter_546'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out = 'experiments/{}_only/{}@{}_lu_{}_iter_{}'.format(_arch, _dataset, _n_labeled, _lambda_u, _train_iteration)\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e856462c-82ac-4300-a2ed-df226421f646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc5d03e-0601-463d-b686-f8e710f9fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1583745484"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e19dd-60f1-4120-b473-65b73342c60d",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89657f49-dd3a-4cf7-8a14-d45e5f11a4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f451c069350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622c7797-e64b-4043-933f-2ec877a92fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing cifar100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "#Labeled: 10000 #Unlabeled: 35000 #Val: 5000\n"
     ]
    }
   ],
   "source": [
    "print(f'==> Preparing cifar100')\n",
    "transform_train = transforms.Compose([\n",
    "    dataset.RandomPadandCrop(32),\n",
    "    dataset.RandomFlip(),\n",
    "    dataset.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    dataset.ToTensor(),\n",
    "])\n",
    "datadir = Path().home() / \"dataset\"\n",
    "\n",
    "batch_size=_batch_size\n",
    "\n",
    "# measure time for data pre-processing\n",
    "start_time = time.time()\n",
    "\n",
    "train_labeled_set, train_unlabeled_set, val_set, test_set = dataset.get_cifar100(datadir, _n_labeled, transform_train=transform_train, transform_val=transform_val)\n",
    "labeled_trainloader = data.DataLoader(train_labeled_set, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "unlabeled_trainloader = data.DataLoader(train_unlabeled_set, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\"\"\"\n",
    "test_loader = data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\"\"\"\n",
    "indices = np.random.choice(len(test_set), int(0.2 * len(test_set)), replace=False)\n",
    "subset_test_set = Subset(test_set, indices)\n",
    "test_loader = data.DataLoader(subset_test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05c26ecc-7991-4d55-a4c3-f48fce0828a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100_labeled\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /home/dsanyal7/dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               <dataset.cifar100.RandomPadandCrop object at 0x7f440ccc2940>\n",
       "               <dataset.cifar100.RandomFlip object at 0x7f440ccc2970>\n",
       "               <dataset.cifar100.ToTensor object at 0x7f440ccc2a30>\n",
       "           )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32d6e59c-5add-4710-b1db-c654c069f9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea299b71-43e9-4364-9b7e-096b308d39e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100_unlabeled\n",
       "    Number of datapoints: 35000\n",
       "    Root location: /home/dsanyal7/dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: <dataset.cifar100.TransformTwice object at 0x7f4509bf6b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unlabeled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5fe6e0-c6f3-44cf-b354-baa0b0ed0ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aec0abb4-7c83-43b2-8ac2-e8787dfb8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_.get_mean_and_std(train_labeled_set)\n",
    "\n",
    "# expected values:\n",
    "# (tensor([ 2.1660e-05, -8.8033e-04,  1.0356e-03]),\n",
    "# tensor([0.8125, 0.8125, 0.7622]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15215480-3dc9-4e0c-a436-b10ed9c92de2",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374cfee5-12b5-423e-97f8-d4392f80a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch: vgg19, pretrained: True, n_classes: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsanyal7/miniconda3/envs/mia/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dsanyal7/miniconda3/envs/mia/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not freeze layers for model: vgg19\n",
      "arch: vgg19, pretrained: True, n_classes: 100\n",
      "Do not freeze layers for model: vgg19\n"
     ]
    }
   ],
   "source": [
    "def create_model(ema=False):\n",
    "    model = models.network(_arch, pretrained=True, n_classes=_n_classes)\n",
    "    model = model.cuda()\n",
    "\n",
    "    if ema:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "ema_model = create_model(ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eadca15-2643-488d-ac28-820a5daaf773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 139.98M\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d28b612-7379-4cdd-be6b-7aa9fcf9bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_rampup(current, rampup_length=_epochs):\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current / rampup_length, 0.0, 1.0)\n",
    "        return float(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6ef8d9b-d09d-4ace-a16f-a01b2f2ae803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeigthEMA(object):\n",
    "    def __init__(self, model, ema_model, alpha=0.999):\n",
    "        self.model = model\n",
    "        self.ema_model = ema_model\n",
    "        self.alpha = alpha\n",
    "        self.params = list(model.state_dict().values())\n",
    "        self.ema_params = list(ema_model.state_dict().values())\n",
    "        self.wd = 0.02 * _lr # for lr=0.02, wd = 0.0004\n",
    "\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            param.data.copy_(ema_param.data)\n",
    "\n",
    "    def step(self):\n",
    "        one_minus_alpha = 1.0 - self.alpha\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            if ema_param.dtype==torch.float32:\n",
    "                ema_param.mul_(self.alpha)\n",
    "                ema_param.add_(param * one_minus_alpha)\n",
    "                # customized weight decay (TODO: should carefully set up)\n",
    "                # \n",
    "                # lr=0.02 -> (0.9996)^5928 (1 epoch): 0.09332.\n",
    "                # lr=0.002 -> (0.99996)^5928 (1 epoch): 0.78889\n",
    "                # param.mul_(1 - self.wd) # x 0.9996 (for lr=0.02), x0.99996 (for lr=0\n",
    "\n",
    "class CustomLoss(object):\n",
    "    def __call__(self, outputs_x, targets_x, outputs_u, targets_u, epoch):\n",
    "        \"\"\"\n",
    "        probs_u = torch.softmax(outputs_u, dim=1)\n",
    "        \"\"\"\n",
    "        \n",
    "        Lx = -torch.mean(torch.sum(F.log_softmax(outputs_x, dim=1) * targets_x, dim=1))\n",
    "        \n",
    "        # CHECK\n",
    "        \"\"\"\n",
    "        Lu = torch.mean((probs_u - targets_u)**2)\n",
    "        w = _lambda_u * linear_rampup(epoch) # _lambda_u: 75 (default)\n",
    "        \"\"\" \n",
    "        Lu = 0\n",
    "        w = 0\n",
    "\n",
    "        return Lx, Lu, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d73f9578-3b1d-4af5-b91d-1166b638e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=_lr, momentum=0.9, weight_decay=5e-4)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=_epochs)\n",
    "\n",
    "ema_optim = WeigthEMA(model, ema_model, alpha=_ema_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9495f15b-90ca-4652-af79-9dd31e517db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acc(model, dl):\n",
    "    acc = []\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        acc.append(torch.argmax(model(x), dim=1) == y)\n",
    "    acc = torch.cat(acc)\n",
    "    acc = torch.sum(acc) / len(acc)\n",
    "\n",
    "    return acc.item()\n",
    "\n",
    "def interleave_offsets(batch, nu):\n",
    "    groups = [batch // (nu + 1)] * (nu + 1)\n",
    "    for x in range(batch - sum(groups)):\n",
    "        groups[-x - 1] += 1\n",
    "    offsets = [0]\n",
    "    for g in groups:\n",
    "        offsets.append(offsets[-1] + g)\n",
    "    assert offsets[-1] == batch\n",
    "    return offsets\n",
    "\n",
    "def interleave(xy, batch):\n",
    "    nu = len(xy) - 1\n",
    "    offsets = interleave_offsets(batch, nu)\n",
    "    xy = [[v[offsets[p]:offsets[p + 1]] for p in range(nu + 1)] for v in xy]\n",
    "    for i in range(1, nu + 1):\n",
    "        xy[0][i], xy[i][i] = xy[i][i], xy[0][i]\n",
    "    return [torch.cat(v, dim=0) for v in xy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "babd8351-ccd2-483f-912a-034133111b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(labeled_trainloader, unlabeled_trainloader, model, optimizer, ema_optimizer, criterion, epoch, use_cuda):\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    losses_x = AverageMeter()\n",
    "    losses_u = AverageMeter()\n",
    "    ws = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    bar = Bar('Training', max=_train_iteration)\n",
    "    labeled_train_iter = iter(labeled_trainloader)\n",
    "    unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    with tqdm(range(_train_iteration), desc=\"Training Progress\", unit=\"batch\") as progress_bar:\n",
    "        for batch_idx in progress_bar:\n",
    "            try:\n",
    "                inputs_x, targets_x = next(labeled_train_iter)\n",
    "            except:\n",
    "                labeled_train_iter = iter(labeled_trainloader)\n",
    "                inputs_x, targets_x = next(labeled_train_iter)\n",
    "\n",
    "            \"\"\"\n",
    "            try:\n",
    "                (inputs_u, inputs_u2), _ = next(unlabeled_train_iter) # two different augment(x)s;\n",
    "            except:\n",
    "                unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "                (inputs_u, inputs_u2), _ = next(unlabeled_train_iter)\n",
    "                \"\"\"\n",
    "    \n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            \n",
    "            batch_size = inputs_x.size(0)\n",
    "    \n",
    "            # convert label to one-hot\n",
    "            targets_x = torch.zeros(batch_size, _n_classes).scatter_(1, targets_x.view(-1,1).long(), 1)\n",
    "    \n",
    "            if use_cuda:\n",
    "                inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda(non_blocking=True)\n",
    "                \"\"\"\n",
    "                inputs_u = inputs_u.cuda()\n",
    "                inputs_u2 = inputs_u2.cuda()\n",
    "                \"\"\"\n",
    "\n",
    "            \"\"\"\n",
    "            with torch.no_grad():\n",
    "                # compute guessed labels of unlabel samples\n",
    "                outputs_u = model(inputs_u)\n",
    "                outputs_u2 = model(inputs_u2)\n",
    "                p = (torch.softmax(outputs_u, dim=1) + torch.softmax(outputs_u2, dim=1)) / 2\n",
    "                pt = p**(1/_T)\n",
    "                targets_u = pt / pt.sum(dim=1, keepdim=True)\n",
    "                targets_u = targets_u.detach()\n",
    "            \"\"\"\n",
    "            \n",
    "            # mixup \n",
    "            \"\"\" \n",
    "            all_inputs = torch.cat([inputs_x, inputs_u, inputs_u2], dim=0)\n",
    "            all_targets = torch.cat([targets_x, targets_u, targets_u], dim=0)\n",
    "            \"\"\"\n",
    "            all_inputs = torch.cat([inputs_x], dim=0)\n",
    "            all_targets = torch.cat([targets_x], dim=0)\n",
    "\n",
    "            # CHECK: \n",
    "            \"\"\"\n",
    "            l = np.random.beta(_alpha, _alpha)\n",
    "            \"\"\"\n",
    "            l = 1\n",
    "            l = max(l, 1-l)\n",
    "            \n",
    "            idx = torch.randperm(all_inputs.size(0))\n",
    "            \n",
    "            input_a, input_b = all_inputs, all_inputs[idx]\n",
    "            target_a, target_b = all_targets, all_targets[idx]\n",
    "            \n",
    "            # input_a > input_b is guaranteed.\n",
    "            mixed_input = l * input_a + (1 - l) * input_b\n",
    "            mixed_target = l * target_a + (1 - l) * target_b\n",
    "\n",
    "            \"\"\"\n",
    "            # interleave labeled and unlabed samples between batches to get correct batchnorm calculation \n",
    "            mixed_input = list(torch.split(mixed_input, batch_size))\n",
    "            mixed_input = interleave(mixed_input, batch_size)\n",
    "            \"\"\"\n",
    "\n",
    "            \"\"\"\n",
    "            logits = [model(mixed_input[0])]\n",
    "            for input in mixed_input[1:]:\n",
    "                logits.append(model(input))\n",
    "            \"\"\"\n",
    "            logits = [model(mixed_input)]\n",
    "    \n",
    "            # put interleaved samples back\n",
    "            \"\"\"\n",
    "            logits = interleave(logits, batch_size)\n",
    "            logits_x = logits[0]\n",
    "            logits_u = torch.cat(logits[1:], dim=0)\n",
    "            \"\"\"\n",
    "            logits_x = logits[0]\n",
    "\n",
    "            \"\"\"\n",
    "            Lx, Lu, w = criterion(logits_x, mixed_target[:batch_size], logits_u, mixed_target[batch_size:], epoch+batch_idx/_train_iteration)\n",
    "            \"\"\"\n",
    "            Lx, Lu, w = criterion(logits_x, mixed_target[:batch_size], None, None, epoch+batch_idx/_train_iteration)\n",
    "    \n",
    "            loss = Lx + w * Lu\n",
    "    \n",
    "            losses.update(loss, inputs_x.size(0))\n",
    "            losses_x.update(Lx, inputs_x.size(0))\n",
    "            losses_u.update(Lu, inputs_x.size(0))\n",
    "            ws.update(w, inputs_x.size(0))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            # CHECK \n",
    "            # ema_optimizer.step()\n",
    "    \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        \n",
    "            # plot progress\n",
    "            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | Loss_x: {loss_x:.4f} | Loss_u: {loss_u:.4f} | W: {w:.4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=_train_iteration,\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=losses.avg,\n",
    "                        loss_x=losses_x.avg,\n",
    "                        loss_u=losses_u.avg,\n",
    "                        w=ws.avg,\n",
    "                        )\n",
    "            bar.next()\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                \"Data\": f\"{data_time.avg:.3f}s\",\n",
    "                \"Batch\": f\"{batch_time.avg:.3f}s\",\n",
    "                \"Total\": bar.elapsed_td,\n",
    "                \"ETA\": bar.eta_td,\n",
    "                \"Loss\": f\"{losses.avg:.4f}\",\n",
    "                \"Loss_x\": f\"{losses_x.avg:.4f}\",\n",
    "                \"Loss_u\": f\"{losses_u.avg:.4f}\",\n",
    "                \"W\": f\"{ws.avg:.4f}\",\n",
    "            })\n",
    "            \n",
    "        bar.finish()\n",
    "    \n",
    "    return (losses.avg, losses_x.avg, losses_u.avg,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69624bbd-d585-4cf5-9cd2-c8981f92abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valloader, model, criterion, epoch, use_cuda, mode):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    bar = Bar(f'{mode}', max=len(valloader))\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(prec1.item(), inputs.size(0))\n",
    "            top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # plot progress\n",
    "            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(valloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        )\n",
    "            bar.next()\n",
    "        bar.finish()\n",
    "        \n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e10b10cf-e28d-494c-9124-25ce540d1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = CustomLoss()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3365861a-a9de-4b6c-81c8-533cec870129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 36.99batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=3.4829, Loss_x=3.4829, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] (naive) Test Accuracy: 0.2355\n",
      "[Epoch 0] Test Accuracy: 23.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.23batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=2.8443, Loss_x=2.8443, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] (naive) Test Accuracy: 0.3115\n",
      "[Epoch 1] Test Accuracy: 31.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.56batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=2.5119, Loss_x=2.5119, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] (naive) Test Accuracy: 0.3365\n",
      "[Epoch 2] Test Accuracy: 33.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.25batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=2.3409, Loss_x=2.3409, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] (naive) Test Accuracy: 0.3725\n",
      "[Epoch 3] Test Accuracy: 37.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.41batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=2.1469, Loss_x=2.1469, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] (naive) Test Accuracy: 0.3795\n",
      "[Epoch 4] Test Accuracy: 37.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.62batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=2.0017, Loss_x=2.0017, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] (naive) Test Accuracy: 0.3845\n",
      "[Epoch 5] Test Accuracy: 38.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.47batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=1.8840, Loss_x=1.8840, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] (naive) Test Accuracy: 0.4110\n",
      "[Epoch 6] Test Accuracy: 41.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.06batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=1.8055, Loss_x=1.8055, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] (naive) Test Accuracy: 0.4175\n",
      "[Epoch 7] Test Accuracy: 41.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.15batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=1.6764, Loss_x=1.6764, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] (naive) Test Accuracy: 0.4240\n",
      "[Epoch 8] Test Accuracy: 42.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.29batch/s, Data=0.018s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=1.5831, Loss_x=1.5831, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] (naive) Test Accuracy: 0.4240\n",
      "[Epoch 9] Test Accuracy: 42.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.89batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=1.5554, Loss_x=1.5554, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] (naive) Test Accuracy: 0.4310\n",
      "[Epoch 10] Test Accuracy: 43.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.79batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=1.4238, Loss_x=1.4238, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] (naive) Test Accuracy: 0.4555\n",
      "[Epoch 11] Test Accuracy: 45.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.06batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=1.3272, Loss_x=1.3272, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] (naive) Test Accuracy: 0.4345\n",
      "[Epoch 12] Test Accuracy: 43.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.47batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=1.2591, Loss_x=1.2591, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] (naive) Test Accuracy: 0.4550\n",
      "[Epoch 13] Test Accuracy: 45.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.14batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=1.1895, Loss_x=1.1895, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] (naive) Test Accuracy: 0.4425\n",
      "[Epoch 14] Test Accuracy: 44.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.13batch/s, Data=0.020s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=1.0982, Loss_x=1.0982, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] (naive) Test Accuracy: 0.4560\n",
      "[Epoch 15] Test Accuracy: 45.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.60batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.9961, Loss_x=0.9961, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] (naive) Test Accuracy: 0.4710\n",
      "[Epoch 16] Test Accuracy: 47.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.13batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.9166, Loss_x=0.9166, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] (naive) Test Accuracy: 0.4720\n",
      "[Epoch 17] Test Accuracy: 47.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.03batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.8338, Loss_x=0.8338, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] (naive) Test Accuracy: 0.4795\n",
      "[Epoch 18] Test Accuracy: 47.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.18batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=0.7650, Loss_x=0.7650, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] (naive) Test Accuracy: 0.4840\n",
      "[Epoch 19] Test Accuracy: 48.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.45batch/s, Data=0.020s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=0.6781, Loss_x=0.6781, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] (naive) Test Accuracy: 0.4920\n",
      "[Epoch 20] Test Accuracy: 49.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.70batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.6018, Loss_x=0.6018, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] (naive) Test Accuracy: 0.4820\n",
      "[Epoch 21] Test Accuracy: 48.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.29batch/s, Data=0.020s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=0.5338, Loss_x=0.5338, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] (naive) Test Accuracy: 0.5090\n",
      "[Epoch 22] Test Accuracy: 50.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.74batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.4862, Loss_x=0.4862, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] (naive) Test Accuracy: 0.4780\n",
      "[Epoch 23] Test Accuracy: 47.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.18batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.3941, Loss_x=0.3941, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] (naive) Test Accuracy: 0.5050\n",
      "[Epoch 24] Test Accuracy: 50.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.25batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.3143, Loss_x=0.3143, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] (naive) Test Accuracy: 0.5240\n",
      "[Epoch 25] Test Accuracy: 52.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.40batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=0.2766, Loss_x=0.2766, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] (naive) Test Accuracy: 0.5070\n",
      "[Epoch 26] Test Accuracy: 50.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.36batch/s, Data=0.019s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=0.2184, Loss_x=0.2184, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] (naive) Test Accuracy: 0.5190\n",
      "[Epoch 27] Test Accuracy: 51.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.97batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.1813, Loss_x=0.1813, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] (naive) Test Accuracy: 0.5030\n",
      "[Epoch 28] Test Accuracy: 50.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.81batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.1405, Loss_x=0.1405, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] (naive) Test Accuracy: 0.5085\n",
      "[Epoch 29] Test Accuracy: 50.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.58batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.1084, Loss_x=0.1084, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] (naive) Test Accuracy: 0.5185\n",
      "[Epoch 30] Test Accuracy: 51.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.48batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0812, Loss_x=0.0812, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] (naive) Test Accuracy: 0.5160\n",
      "[Epoch 31] Test Accuracy: 51.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.17batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0529, Loss_x=0.0529, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] (naive) Test Accuracy: 0.5275\n",
      "[Epoch 32] Test Accuracy: 52.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.43batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0367, Loss_x=0.0367, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] (naive) Test Accuracy: 0.5405\n",
      "[Epoch 33] Test Accuracy: 54.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.68batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0259, Loss_x=0.0259, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] (naive) Test Accuracy: 0.5430\n",
      "[Epoch 34] Test Accuracy: 54.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.17batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0223, Loss_x=0.0223, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] (naive) Test Accuracy: 0.5515\n",
      "[Epoch 35] Test Accuracy: 55.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.30batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0119, Loss_x=0.0119, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36] (naive) Test Accuracy: 0.5385\n",
      "[Epoch 36] Test Accuracy: 53.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.46batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0103, Loss_x=0.0103, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37] (naive) Test Accuracy: 0.5360\n",
      "[Epoch 37] Test Accuracy: 53.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.80batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0052, Loss_x=0.0052, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38] (naive) Test Accuracy: 0.5510\n",
      "[Epoch 38] Test Accuracy: 55.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.55batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0056, Loss_x=0.0056, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39] (naive) Test Accuracy: 0.5450\n",
      "[Epoch 39] Test Accuracy: 54.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.83batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0048, Loss_x=0.0048, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40] (naive) Test Accuracy: 0.5485\n",
      "[Epoch 40] Test Accuracy: 54.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.82batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0035, Loss_x=0.0035, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41] (naive) Test Accuracy: 0.5545\n",
      "[Epoch 41] Test Accuracy: 55.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.69batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0036, Loss_x=0.0036, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42] (naive) Test Accuracy: 0.5560\n",
      "[Epoch 42] Test Accuracy: 55.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.01batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0028, Loss_x=0.0028, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43] (naive) Test Accuracy: 0.5575\n",
      "[Epoch 43] Test Accuracy: 55.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 36.64batch/s, Data=0.019s, Batch=0.028s, Total=0:00:15, ETA=0:00:00, Loss=0.0025, Loss_x=0.0025, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44] (naive) Test Accuracy: 0.5580\n",
      "[Epoch 44] Test Accuracy: 55.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.43batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0031, Loss_x=0.0031, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45] (naive) Test Accuracy: 0.5595\n",
      "[Epoch 45] Test Accuracy: 55.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.08batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0025, Loss_x=0.0025, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46] (naive) Test Accuracy: 0.5620\n",
      "[Epoch 46] Test Accuracy: 56.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 38.31batch/s, Data=0.020s, Batch=0.026s, Total=0:00:14, ETA=0:00:00, Loss=0.0025, Loss_x=0.0025, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47] (naive) Test Accuracy: 0.5600\n",
      "[Epoch 47] Test Accuracy: 56.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.75batch/s, Data=0.019s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0021, Loss_x=0.0021, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48] (naive) Test Accuracy: 0.5605\n",
      "[Epoch 48] Test Accuracy: 56.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 546/546 [00:14<00:00, 37.47batch/s, Data=0.020s, Batch=0.027s, Total=0:00:14, ETA=0:00:00, Loss=0.0028, Loss_x=0.0028, Loss_u=0.0000, W=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49] (naive) Test Accuracy: 0.5600\n",
      "[Epoch 49] Test Accuracy: 56.0000\n",
      "Best acc:\n",
      "0.0\n",
      "Mean acc:\n",
      "54.720000000000006\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(_out):\n",
    "    mkdir_p(_out)\n",
    "\n",
    "title = 'noisy-cifar-10'\n",
    "\n",
    "logger = Logger(os.path.join(_out, 'log.txt'), title=title)\n",
    "logger.set_names(['Train Loss', 'Train Loss X', 'Train Loss U',  'Valid Loss', 'Valid Acc.', 'Test Loss', 'Test Acc.'])\n",
    "writer = SummaryWriter(_out)\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "step = 0\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(_epochs):\n",
    "\n",
    "    train_loss, train_loss_x, train_loss_u = train(labeled_trainloader, unlabeled_trainloader, model, optim, ema_optim, train_criterion, epoch, use_cuda)\n",
    "    \"\"\"\n",
    "    _, train_acc = validate(labeled_trainloader, ema_model, criterion, epoch, use_cuda, mode='Train Stats')\n",
    "    val_loss, val_acc = validate(val_loader, ema_model, criterion, epoch, use_cuda, mode='Valid Stats')\n",
    "    test_loss, test_acc = validate(test_loader, ema_model, criterion, epoch, use_cuda, mode='Test Stats ')\n",
    "    \"\"\"\n",
    "    _, train_acc = 0.0, 0.0\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    test_loss, test_acc = validate(test_loader, model, criterion, epoch, use_cuda, mode='Test Stats ')\n",
    "\n",
    "    sched.step()\n",
    "\n",
    "    _test_acc = get_acc(model, test_loader)\n",
    "    \"\"\"\n",
    "    print(f\"[Epoch {epoch}] (naive) Test Accuracy: {_test_acc:.4f}\")\n",
    "    print(f\"[Epoch {epoch}] Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"[Epoch {epoch}] Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"[Epoch {epoch}] Test Accuracy: {test_acc:.4f}\")\n",
    "    \"\"\"\n",
    "    print(f\"[Epoch {epoch}] (naive) Test Accuracy: {_test_acc:.4f}\")\n",
    "    print(f\"[Epoch {epoch}] Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    \n",
    "    step = _train_iteration * (epoch + 1)\n",
    "\n",
    "    writer.add_scalar('losses/train_loss', train_loss, step)\n",
    "    writer.add_scalar('losses/valid_loss', val_loss, step)\n",
    "    writer.add_scalar('losses/test_loss', test_loss, step)\n",
    "\n",
    "    writer.add_scalar('accuracy/train_acc', train_acc, step)\n",
    "    writer.add_scalar('accuracy/val_acc', val_acc, step)\n",
    "    writer.add_scalar('accuracy/test_acc', test_acc, step)\n",
    "\n",
    "    logger.append([train_loss, train_loss_x, train_loss_u, val_loss, val_acc, test_loss, test_acc])\n",
    "\n",
    "    best_acc = max(val_acc, best_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "logger.close()\n",
    "writer.close()\n",
    "\n",
    "print('Best acc:')\n",
    "print(best_acc)\n",
    "\n",
    "print('Mean acc:')\n",
    "print(np.mean(test_accs[-20:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb67fc-c769-44de-ae04-3e94b66ffbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
