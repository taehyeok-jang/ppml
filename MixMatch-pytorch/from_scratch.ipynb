{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee8fbd1-0da2-4f99-8472-ff6a76fcf907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime \n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.utils.data as data # for code compatibility\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "import timm\n",
    "\n",
    "import scipy.stats\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# util\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# customized \n",
    "import models.arch as models\n",
    "import dataset.cifar10 as dataset\n",
    "\n",
    "from utils import Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from progress.bar import Bar as Bar\n",
    "import utils as utils_\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "##\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e131e4c8-44de-48a2-8262-febbe8fabe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vit_large_patch16_224_cifar10, CIFAR-10\n",
    "'''\n",
    "lr=0.02\n",
    "epochs=25\n",
    "n_shadows = 64\n",
    "shadow_id = -1 \n",
    "model = \"efficientnet_b7\"\n",
    "dataset = \"cifar100\"\n",
    "pkeep = 0.5\n",
    "savedir = f\"exp/{model}_{dataset}\"\n",
    "debug = True\n",
    "'''\n",
    "\n",
    "# for vgg19, CIFAR-10\n",
    "_lr = 0.02\n",
    "_epochs = 50\n",
    "_arch = \"vgg19\"\n",
    "_dataset = \"cifar10\"\n",
    "_n_classes = 10 # depend on dataset\n",
    "_debug = True\n",
    "_batch_size = 64\n",
    "\n",
    "_n_labeled = 10000\n",
    "_alpha = 0.75\n",
    "_lambda_u = 20 # default: 75\n",
    "\n",
    "_ema_decay = 0.999 # default: 0.999\n",
    "_T = 0.5 # default: 0.5\n",
    "_train_iteration = int(_n_labeled / _batch_size) # phase 1: support full-supervised learning, default: 1024\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7019f1-f206-43c4-bb26-556167d635e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cifar10@10000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out = 'cifar10@%d' % (_n_labeled)\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e856462c-82ac-4300-a2ed-df226421f646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc5d03e-0601-463d-b686-f8e710f9fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1583745484"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e19dd-60f1-4120-b473-65b73342c60d",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89657f49-dd3a-4cf7-8a14-d45e5f11a4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f93b3c462f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622c7797-e64b-4043-933f-2ec877a92fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "#Labeled: 10000 #Unlabeled: 35000 #Val: 5000\n"
     ]
    }
   ],
   "source": [
    "print(f'==> Preparing cifar10')\n",
    "transform_train = transforms.Compose([\n",
    "    dataset.RandomPadandCrop(32),\n",
    "    dataset.RandomFlip(),\n",
    "    dataset.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    dataset.ToTensor(),\n",
    "])\n",
    "datadir = Path().home() / \"dataset\"\n",
    "\n",
    "batch_size=_batch_size\n",
    "\n",
    "train_labeled_set, train_unlabeled_set, val_set, test_set = dataset.get_cifar10(datadir, _n_labeled, transform_train=transform_train, transform_val=transform_val)\n",
    "labeled_trainloader = data.DataLoader(train_labeled_set, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "unlabeled_trainloader = data.DataLoader(train_unlabeled_set, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c26ecc-7991-4d55-a4c3-f48fce0828a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10_labeled\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /home/dsanyal7/dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               <dataset.cifar10.RandomPadandCrop object at 0x7f93a17d7880>\n",
       "               <dataset.cifar10.RandomFlip object at 0x7f92a48a6670>\n",
       "               <dataset.cifar10.ToTensor object at 0x7f92a48a66a0>\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea299b71-43e9-4364-9b7e-096b308d39e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10_unlabeled\n",
       "    Number of datapoints: 35000\n",
       "    Root location: /home/dsanyal7/dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: <dataset.cifar10.TransformTwice object at 0x7f93a17d7730>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unlabeled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec0abb4-7c83-43b2-8ac2-e8787dfb8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_.get_mean_and_std(train_labeled_set)\n",
    "\n",
    "# expected values:\n",
    "# (tensor([ 2.1660e-05, -8.8033e-04,  1.0356e-03]),\n",
    "# tensor([0.8125, 0.8125, 0.7622]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15215480-3dc9-4e0c-a436-b10ed9c92de2",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "374cfee5-12b5-423e-97f8-d4392f80a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch: vgg19, pretrained: False, n_classes: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsanyal7/miniconda3/envs/mia/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dsanyal7/miniconda3/envs/mia/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch: vgg19, pretrained: False, n_classes: 10\n"
     ]
    }
   ],
   "source": [
    "def create_model(ema=False):\n",
    "    model = models.network(_arch, pretrained=False, n_classes=_n_classes)\n",
    "    model = model.cuda()\n",
    "\n",
    "    if ema:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "ema_model = create_model(ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eadca15-2643-488d-ac28-820a5daaf773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 139.61M\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d28b612-7379-4cdd-be6b-7aa9fcf9bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_rampup(current, rampup_length=_epochs):\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current / rampup_length, 0.0, 1.0)\n",
    "        return float(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ef8d9b-d09d-4ace-a16f-a01b2f2ae803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeigthEMA(object):\n",
    "    def __init__(self, model, ema_model, alpha=0.999):\n",
    "        self.model = model\n",
    "        self.ema_model = ema_model\n",
    "        self.alpha = alpha\n",
    "        self.params = list(model.state_dict().values())\n",
    "        self.ema_params = list(ema_model.state_dict().values())\n",
    "        self.wd = 0.02 * _lr # for lr=0.02, wd = 0.0004\n",
    "\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            param.data.copy_(ema_param.data)\n",
    "\n",
    "    def step(self):\n",
    "        one_minus_alpha = 1.0 - self.alpha\n",
    "        for param, ema_param in zip(self.params, self.ema_params):\n",
    "            if ema_param.dtype==torch.float32:\n",
    "                ema_param.mul_(self.alpha)\n",
    "                ema_param.add_(param * one_minus_alpha)\n",
    "                # customized weight decay (TODO: should carefully set up)\n",
    "                # \n",
    "                # lr=0.02 -> (0.9996)^5928 (1 epoch): 0.09332.\n",
    "                # lr=0.002 -> (0.99996)^5928 (1 epoch): 0.78889\n",
    "                # param.mul_(1 - self.wd) # x 0.9996 (for lr=0.02), x0.99996 (for lr=0\n",
    "\n",
    "class CustomLoss(object):\n",
    "    def __call__(self, outputs_x, targets_x, outputs_u, targets_u, epoch):\n",
    "        probs_u = torch.softmax(outputs_u, dim=1)\n",
    "        \n",
    "        Lx = -torch.mean(torch.sum(F.log_softmax(outputs_x, dim=1) * targets_x, dim=1))\n",
    "        Lu = torch.mean((probs_u - targets_u)**2)\n",
    "\n",
    "        w = _lambda_u * linear_rampup(epoch) # _lambda_u: 75 (default)\n",
    "\n",
    "        return Lx, Lu, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d73f9578-3b1d-4af5-b91d-1166b638e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=_lr, momentum=0.9, weight_decay=5e-4)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=_epochs)\n",
    "\n",
    "ema_optim = WeigthEMA(model, ema_model, alpha=_ema_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9495f15b-90ca-4652-af79-9dd31e517db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acc(model, dl):\n",
    "    acc = []\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        acc.append(torch.argmax(model(x), dim=1) == y)\n",
    "    acc = torch.cat(acc)\n",
    "    acc = torch.sum(acc) / len(acc)\n",
    "\n",
    "    return acc.item()\n",
    "\n",
    "def interleave_offsets(batch, nu):\n",
    "    groups = [batch // (nu + 1)] * (nu + 1)\n",
    "    for x in range(batch - sum(groups)):\n",
    "        groups[-x - 1] += 1\n",
    "    offsets = [0]\n",
    "    for g in groups:\n",
    "        offsets.append(offsets[-1] + g)\n",
    "    assert offsets[-1] == batch\n",
    "    return offsets\n",
    "\n",
    "def interleave(xy, batch):\n",
    "    nu = len(xy) - 1\n",
    "    offsets = interleave_offsets(batch, nu)\n",
    "    xy = [[v[offsets[p]:offsets[p + 1]] for p in range(nu + 1)] for v in xy]\n",
    "    for i in range(1, nu + 1):\n",
    "        xy[0][i], xy[i][i] = xy[i][i], xy[0][i]\n",
    "    return [torch.cat(v, dim=0) for v in xy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babd8351-ccd2-483f-912a-034133111b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(labeled_trainloader, unlabeled_trainloader, model, optimizer, ema_optimizer, criterion, epoch, use_cuda):\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    losses_x = AverageMeter()\n",
    "    losses_u = AverageMeter()\n",
    "    ws = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    bar = Bar('Training', max=_train_iteration)\n",
    "    labeled_train_iter = iter(labeled_trainloader)\n",
    "    unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    with tqdm(range(_train_iteration), desc=\"Training Progress\", unit=\"batch\") as progress_bar:\n",
    "        for batch_idx in progress_bar:\n",
    "    \n",
    "            inputs_x, targets_x      = next(labeled_train_iter)\n",
    "            (inputs_u, inputs_u2), _ = next(unlabeled_train_iter)\n",
    "    \n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            \n",
    "            batch_size = inputs_x.size(0)\n",
    "    \n",
    "            # convert label to one-hot\n",
    "            targets_x = torch.zeros(batch_size, _n_classes).scatter_(1, targets_x.view(-1,1).long(), 1)\n",
    "    \n",
    "            if use_cuda:\n",
    "                inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda(non_blocking=True)\n",
    "                inputs_u = inputs_u.cuda()\n",
    "                inputs_u2 = inputs_u2.cuda()\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # compute guessed labels of unlabel samples\n",
    "                outputs_u = model(inputs_u)\n",
    "                outputs_u2 = model(inputs_u2)\n",
    "                p = (torch.softmax(outputs_u, dim=1) + torch.softmax(outputs_u2, dim=1)) / 2\n",
    "                pt = p**(1/_T)\n",
    "                targets_u = pt / pt.sum(dim=1, keepdim=True)\n",
    "                targets_u = targets_u.detach()\n",
    "            \n",
    "            # mixup \n",
    "            all_inputs = torch.cat([inputs_x, inputs_u, inputs_u2], dim=0)\n",
    "            all_targets = torch.cat([targets_x, targets_u, targets_u], dim=0)\n",
    "    \n",
    "            l = np.random.beta(_alpha, _alpha)\n",
    "            # l = 1\n",
    "            l = max(l, 1-l)\n",
    "            \n",
    "            idx = torch.randperm(all_inputs.size(0))\n",
    "            \n",
    "            input_a, input_b = all_inputs, all_inputs[idx]\n",
    "            target_a, target_b = all_targets, all_targets[idx]\n",
    "            \n",
    "            # input_a > input_b is guaranteed.\n",
    "            mixed_input = l * input_a + (1 - l) * input_b\n",
    "            mixed_target = l * target_a + (1 - l) * target_b\n",
    "    \n",
    "            # interleave labeled and unlabed samples between batches to get correct batchnorm calculation \n",
    "            mixed_input = list(torch.split(mixed_input, batch_size))\n",
    "            mixed_input = interleave(mixed_input, batch_size)\n",
    "            \n",
    "            logits = [model(mixed_input[0])]\n",
    "            for input in mixed_input[1:]:\n",
    "                logits.append(model(input))\n",
    "    \n",
    "            # put interleaved samples back\n",
    "            logits = interleave(logits, batch_size)\n",
    "            logits_x = logits[0]\n",
    "            logits_u = torch.cat(logits[1:], dim=0)\n",
    "    \n",
    "            Lx, Lu, w = criterion(logits_x, mixed_target[:batch_size], logits_u, mixed_target[batch_size:], epoch+batch_idx/_train_iteration)\n",
    "    \n",
    "            loss = Lx + w * Lu\n",
    "    \n",
    "            losses.update(loss, inputs_x.size(0))\n",
    "            losses_x.update(Lx, inputs_x.size(0))\n",
    "            losses_u.update(Lu, inputs_x.size(0))\n",
    "            ws.update(w, inputs_x.size(0))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            ema_optimizer.step()\n",
    "    \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        \n",
    "            # plot progress\n",
    "            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | Loss_x: {loss_x:.4f} | Loss_u: {loss_u:.4f} | W: {w:.4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=_train_iteration,\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=losses.avg,\n",
    "                        loss_x=losses_x.avg,\n",
    "                        loss_u=losses_u.avg,\n",
    "                        w=ws.avg,\n",
    "                        )\n",
    "            bar.next()\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                \"Data\": f\"{data_time.avg:.3f}s\",\n",
    "                \"Batch\": f\"{batch_time.avg:.3f}s\",\n",
    "                \"Total\": bar.elapsed_td,\n",
    "                \"ETA\": bar.eta_td,\n",
    "                \"Loss\": f\"{losses.avg:.4f}\",\n",
    "                \"Loss_x\": f\"{losses_x.avg:.4f}\",\n",
    "                \"Loss_u\": f\"{losses_u.avg:.4f}\",\n",
    "                \"W\": f\"{ws.avg:.4f}\",\n",
    "            })\n",
    "            \n",
    "        bar.finish()\n",
    "    \n",
    "    return (losses.avg, losses_x.avg, losses_u.avg,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69624bbd-d585-4cf5-9cd2-c8981f92abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valloader, model, criterion, epoch, use_cuda, mode):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    bar = Bar(f'{mode}', max=len(valloader))\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(prec1.item(), inputs.size(0))\n",
    "            top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # plot progress\n",
    "            bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(valloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        )\n",
    "            bar.next()\n",
    "        bar.finish()\n",
    "        \n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10b10cf-e28d-494c-9124-25ce540d1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = CustomLoss()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3365861a-a9de-4b6c-81c8-533cec870129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.62batch/s, Data=0.046s, Batch=0.074s, Total=0:00:11, ETA=0:00:00, Loss=2.2719, Loss_x=2.2713, Loss_u=0.0027, W=0.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] (naive) Test Accuracy: 0.1770\n",
      "[Epoch 0] Train Accuracy: 11.5986\n",
      "[Epoch 0] Validation Accuracy: 11.4200\n",
      "[Epoch 0] Test Accuracy: 11.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.12batch/s, Data=0.046s, Batch=0.071s, Total=0:00:11, ETA=0:00:00, Loss=2.2017, Loss_x=2.1997, Loss_u=0.0033, W=0.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] (naive) Test Accuracy: 0.2145\n",
      "[Epoch 1] Train Accuracy: 15.2244\n",
      "[Epoch 1] Validation Accuracy: 15.7600\n",
      "[Epoch 1] Test Accuracy: 15.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.08batch/s, Data=0.047s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=2.1232, Loss_x=2.1195, Loss_u=0.0037, W=0.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] (naive) Test Accuracy: 0.2389\n",
      "[Epoch 2] Train Accuracy: 12.8806\n",
      "[Epoch 2] Validation Accuracy: 13.0200\n",
      "[Epoch 2] Test Accuracy: 12.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.01batch/s, Data=0.046s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=2.0799, Loss_x=2.0736, Loss_u=0.0045, W=1.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] (naive) Test Accuracy: 0.2749\n",
      "[Epoch 3] Train Accuracy: 13.3814\n",
      "[Epoch 3] Validation Accuracy: 13.5400\n",
      "[Epoch 3] Test Accuracy: 13.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.15batch/s, Data=0.046s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=2.0595, Loss_x=2.0512, Loss_u=0.0046, W=1.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] (naive) Test Accuracy: 0.2733\n",
      "[Epoch 4] Train Accuracy: 14.8538\n",
      "[Epoch 4] Validation Accuracy: 14.8800\n",
      "[Epoch 4] Test Accuracy: 14.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.90batch/s, Data=0.048s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=2.0439, Loss_x=2.0312, Loss_u=0.0058, W=2.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] (naive) Test Accuracy: 0.3002\n",
      "[Epoch 5] Train Accuracy: 17.1174\n",
      "[Epoch 5] Validation Accuracy: 17.5000\n",
      "[Epoch 5] Test Accuracy: 16.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.92batch/s, Data=0.048s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=2.0109, Loss_x=1.9944, Loss_u=0.0063, W=2.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] (naive) Test Accuracy: 0.2799\n",
      "[Epoch 6] Train Accuracy: 19.7616\n",
      "[Epoch 6] Validation Accuracy: 20.5200\n",
      "[Epoch 6] Test Accuracy: 19.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.01batch/s, Data=0.046s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.9912, Loss_x=1.9706, Loss_u=0.0069, W=2.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] (naive) Test Accuracy: 0.3645\n",
      "[Epoch 7] Train Accuracy: 22.1054\n",
      "[Epoch 7] Validation Accuracy: 23.1000\n",
      "[Epoch 7] Test Accuracy: 22.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.97batch/s, Data=0.048s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.9704, Loss_x=1.9463, Loss_u=0.0071, W=3.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] (naive) Test Accuracy: 0.3748\n",
      "[Epoch 8] Train Accuracy: 24.6294\n",
      "[Epoch 8] Validation Accuracy: 25.6800\n",
      "[Epoch 8] Test Accuracy: 25.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.90batch/s, Data=0.048s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.9357, Loss_x=1.9066, Loss_u=0.0076, W=3.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] (naive) Test Accuracy: 0.2978\n",
      "[Epoch 9] Train Accuracy: 27.6342\n",
      "[Epoch 9] Validation Accuracy: 29.2200\n",
      "[Epoch 9] Test Accuracy: 28.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.93batch/s, Data=0.048s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.9290, Loss_x=1.8957, Loss_u=0.0079, W=4.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] (naive) Test Accuracy: 0.3344\n",
      "[Epoch 10] Train Accuracy: 31.0397\n",
      "[Epoch 10] Validation Accuracy: 33.0400\n",
      "[Epoch 10] Test Accuracy: 32.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.94batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.8840, Loss_x=1.8446, Loss_u=0.0086, W=4.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] (naive) Test Accuracy: 0.3969\n",
      "[Epoch 11] Train Accuracy: 35.8073\n",
      "[Epoch 11] Validation Accuracy: 37.5400\n",
      "[Epoch 11] Test Accuracy: 36.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.86batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.9036, Loss_x=1.8537, Loss_u=0.0100, W=4.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] (naive) Test Accuracy: 0.4610\n",
      "[Epoch 12] Train Accuracy: 38.0108\n",
      "[Epoch 12] Validation Accuracy: 40.4000\n",
      "[Epoch 12] Test Accuracy: 39.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.00batch/s, Data=0.048s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.8515, Loss_x=1.7989, Loss_u=0.0097, W=5.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] (naive) Test Accuracy: 0.4837\n",
      "[Epoch 13] Train Accuracy: 41.2059\n",
      "[Epoch 13] Validation Accuracy: 42.8400\n",
      "[Epoch 13] Test Accuracy: 42.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.93batch/s, Data=0.046s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.8450, Loss_x=1.7855, Loss_u=0.0103, W=5.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] (naive) Test Accuracy: 0.4766\n",
      "[Epoch 14] Train Accuracy: 43.5096\n",
      "[Epoch 14] Validation Accuracy: 45.1400\n",
      "[Epoch 14] Test Accuracy: 44.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.97batch/s, Data=0.046s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.7861, Loss_x=1.7215, Loss_u=0.0104, W=6.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] (naive) Test Accuracy: 0.5340\n",
      "[Epoch 15] Train Accuracy: 45.6530\n",
      "[Epoch 15] Validation Accuracy: 47.2400\n",
      "[Epoch 15] Test Accuracy: 47.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.01batch/s, Data=0.047s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.7839, Loss_x=1.7143, Loss_u=0.0105, W=6.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] (naive) Test Accuracy: 0.4641\n",
      "[Epoch 16] Train Accuracy: 48.9083\n",
      "[Epoch 16] Validation Accuracy: 49.4800\n",
      "[Epoch 16] Test Accuracy: 48.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.95batch/s, Data=0.048s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.7610, Loss_x=1.6864, Loss_u=0.0107, W=6.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] (naive) Test Accuracy: 0.5333\n",
      "[Epoch 17] Train Accuracy: 51.0116\n",
      "[Epoch 17] Validation Accuracy: 51.7800\n",
      "[Epoch 17] Test Accuracy: 50.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.95batch/s, Data=0.048s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.7034, Loss_x=1.6219, Loss_u=0.0110, W=7.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] (naive) Test Accuracy: 0.5650\n",
      "[Epoch 18] Train Accuracy: 53.7660\n",
      "[Epoch 18] Validation Accuracy: 53.5000\n",
      "[Epoch 18] Test Accuracy: 52.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.93batch/s, Data=0.046s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.7186, Loss_x=1.6275, Loss_u=0.0117, W=7.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] (naive) Test Accuracy: 0.6063\n",
      "[Epoch 19] Train Accuracy: 55.3786\n",
      "[Epoch 19] Validation Accuracy: 55.9600\n",
      "[Epoch 19] Test Accuracy: 55.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.99batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.6936, Loss_x=1.6002, Loss_u=0.0114, W=8.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] (naive) Test Accuracy: 0.6074\n",
      "[Epoch 20] Train Accuracy: 57.7925\n",
      "[Epoch 20] Validation Accuracy: 57.5400\n",
      "[Epoch 20] Test Accuracy: 56.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.90batch/s, Data=0.049s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.6533, Loss_x=1.5573, Loss_u=0.0112, W=8.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] (naive) Test Accuracy: 0.5939\n",
      "[Epoch 21] Train Accuracy: 59.7556\n",
      "[Epoch 21] Validation Accuracy: 59.2400\n",
      "[Epoch 21] Test Accuracy: 58.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.98batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.6473, Loss_x=1.5448, Loss_u=0.0114, W=8.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] (naive) Test Accuracy: 0.6376\n",
      "[Epoch 22] Train Accuracy: 61.3081\n",
      "[Epoch 22] Validation Accuracy: 60.6800\n",
      "[Epoch 22] Test Accuracy: 60.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.91batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.5872, Loss_x=1.4837, Loss_u=0.0110, W=9.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] (naive) Test Accuracy: 0.6564\n",
      "[Epoch 23] Train Accuracy: 63.1310\n",
      "[Epoch 23] Validation Accuracy: 62.2400\n",
      "[Epoch 23] Test Accuracy: 61.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.96batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.6152, Loss_x=1.4997, Loss_u=0.0118, W=9.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] (naive) Test Accuracy: 0.6719\n",
      "[Epoch 24] Train Accuracy: 64.5933\n",
      "[Epoch 24] Validation Accuracy: 63.8000\n",
      "[Epoch 24] Test Accuracy: 63.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.90batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.6242, Loss_x=1.5028, Loss_u=0.0119, W=10.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] (naive) Test Accuracy: 0.6551\n",
      "[Epoch 25] Train Accuracy: 66.6066\n",
      "[Epoch 25] Validation Accuracy: 65.0600\n",
      "[Epoch 25] Test Accuracy: 64.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.04batch/s, Data=0.048s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.5986, Loss_x=1.4708, Loss_u=0.0121, W=10.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] (naive) Test Accuracy: 0.6458\n",
      "[Epoch 26] Train Accuracy: 67.6382\n",
      "[Epoch 26] Validation Accuracy: 66.0400\n",
      "[Epoch 26] Test Accuracy: 65.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.94batch/s, Data=0.046s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.5566, Loss_x=1.4290, Loss_u=0.0116, W=10.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] (naive) Test Accuracy: 0.7110\n",
      "[Epoch 27] Train Accuracy: 68.7700\n",
      "[Epoch 27] Validation Accuracy: 67.2200\n",
      "[Epoch 27] Test Accuracy: 66.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.73batch/s, Data=0.049s, Batch=0.074s, Total=0:00:11, ETA=0:00:00, Loss=1.4717, Loss_x=1.3444, Loss_u=0.0112, W=11.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] (naive) Test Accuracy: 0.6841\n",
      "[Epoch 28] Train Accuracy: 70.4728\n",
      "[Epoch 28] Validation Accuracy: 67.9800\n",
      "[Epoch 28] Test Accuracy: 67.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.82batch/s, Data=0.049s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4594, Loss_x=1.3305, Loss_u=0.0109, W=11.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] (naive) Test Accuracy: 0.7048\n",
      "[Epoch 29] Train Accuracy: 71.2340\n",
      "[Epoch 29] Validation Accuracy: 68.6800\n",
      "[Epoch 29] Test Accuracy: 68.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.03batch/s, Data=0.045s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.5465, Loss_x=1.3989, Loss_u=0.0121, W=12.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] (naive) Test Accuracy: 0.6998\n",
      "[Epoch 30] Train Accuracy: 72.8866\n",
      "[Epoch 30] Validation Accuracy: 69.5000\n",
      "[Epoch 30] Test Accuracy: 69.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.99batch/s, Data=0.043s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.5036, Loss_x=1.3542, Loss_u=0.0119, W=12.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] (naive) Test Accuracy: 0.7165\n",
      "[Epoch 31] Train Accuracy: 73.7580\n",
      "[Epoch 31] Validation Accuracy: 70.3800\n",
      "[Epoch 31] Test Accuracy: 70.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.79batch/s, Data=0.045s, Batch=0.074s, Total=0:00:11, ETA=0:00:00, Loss=1.5376, Loss_x=1.3786, Loss_u=0.0122, W=12.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] (naive) Test Accuracy: 0.7297\n",
      "[Epoch 32] Train Accuracy: 75.3105\n",
      "[Epoch 32] Validation Accuracy: 70.7800\n",
      "[Epoch 32] Test Accuracy: 70.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.93batch/s, Data=0.049s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.5414, Loss_x=1.3749, Loss_u=0.0124, W=13.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] (naive) Test Accuracy: 0.7364\n",
      "[Epoch 33] Train Accuracy: 76.0817\n",
      "[Epoch 33] Validation Accuracy: 71.3600\n",
      "[Epoch 33] Test Accuracy: 71.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.03batch/s, Data=0.047s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.5061, Loss_x=1.3347, Loss_u=0.0124, W=13.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] (naive) Test Accuracy: 0.7293\n",
      "[Epoch 34] Train Accuracy: 76.8229\n",
      "[Epoch 34] Validation Accuracy: 71.9400\n",
      "[Epoch 34] Test Accuracy: 72.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.92batch/s, Data=0.046s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4685, Loss_x=1.2931, Loss_u=0.0123, W=14.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] (naive) Test Accuracy: 0.7351\n",
      "[Epoch 35] Train Accuracy: 77.6643\n",
      "[Epoch 35] Validation Accuracy: 72.6000\n",
      "[Epoch 35] Test Accuracy: 72.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.89batch/s, Data=0.044s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4531, Loss_x=1.2760, Loss_u=0.0121, W=14.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36] (naive) Test Accuracy: 0.7167\n",
      "[Epoch 36] Train Accuracy: 78.3253\n",
      "[Epoch 36] Validation Accuracy: 73.3400\n",
      "[Epoch 36] Test Accuracy: 73.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.92batch/s, Data=0.049s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4297, Loss_x=1.2555, Loss_u=0.0116, W=14.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37] (naive) Test Accuracy: 0.7538\n",
      "[Epoch 37] Train Accuracy: 79.1066\n",
      "[Epoch 37] Validation Accuracy: 74.1200\n",
      "[Epoch 37] Test Accuracy: 73.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.96batch/s, Data=0.044s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.3933, Loss_x=1.2170, Loss_u=0.0114, W=15.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38] (naive) Test Accuracy: 0.7421\n",
      "[Epoch 38] Train Accuracy: 80.2484\n",
      "[Epoch 38] Validation Accuracy: 74.8800\n",
      "[Epoch 38] Test Accuracy: 74.2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.96batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4953, Loss_x=1.2923, Loss_u=0.0128, W=15.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39] (naive) Test Accuracy: 0.7485\n",
      "[Epoch 39] Train Accuracy: 80.1683\n",
      "[Epoch 39] Validation Accuracy: 75.5800\n",
      "[Epoch 39] Test Accuracy: 74.5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.92batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.3561, Loss_x=1.1714, Loss_u=0.0114, W=16.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40] (naive) Test Accuracy: 0.7616\n",
      "[Epoch 40] Train Accuracy: 80.9195\n",
      "[Epoch 40] Validation Accuracy: 76.0800\n",
      "[Epoch 40] Test Accuracy: 74.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.03batch/s, Data=0.048s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.3922, Loss_x=1.1970, Loss_u=0.0118, W=16.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41] (naive) Test Accuracy: 0.7665\n",
      "[Epoch 41] Train Accuracy: 81.9411\n",
      "[Epoch 41] Validation Accuracy: 76.3000\n",
      "[Epoch 41] Test Accuracy: 75.2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.92batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4353, Loss_x=1.2284, Loss_u=0.0122, W=16.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42] (naive) Test Accuracy: 0.7584\n",
      "[Epoch 42] Train Accuracy: 82.6723\n",
      "[Epoch 42] Validation Accuracy: 76.6200\n",
      "[Epoch 42] Test Accuracy: 75.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.99batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4596, Loss_x=1.2399, Loss_u=0.0126, W=17.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43] (naive) Test Accuracy: 0.7701\n",
      "[Epoch 43] Train Accuracy: 82.9427\n",
      "[Epoch 43] Validation Accuracy: 76.6800\n",
      "[Epoch 43] Test Accuracy: 75.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 14.01batch/s, Data=0.044s, Batch=0.072s, Total=0:00:11, ETA=0:00:00, Loss=1.4016, Loss_x=1.1956, Loss_u=0.0116, W=17.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44] (naive) Test Accuracy: 0.7698\n",
      "[Epoch 44] Train Accuracy: 83.2732\n",
      "[Epoch 44] Validation Accuracy: 76.9600\n",
      "[Epoch 44] Test Accuracy: 76.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.94batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4055, Loss_x=1.1887, Loss_u=0.0119, W=18.1987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45] (naive) Test Accuracy: 0.7763\n",
      "[Epoch 45] Train Accuracy: 84.0345\n",
      "[Epoch 45] Validation Accuracy: 77.1800\n",
      "[Epoch 45] Test Accuracy: 76.3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.95batch/s, Data=0.048s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4113, Loss_x=1.1906, Loss_u=0.0119, W=18.5987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46] (naive) Test Accuracy: 0.7779\n",
      "[Epoch 46] Train Accuracy: 83.7139\n",
      "[Epoch 46] Validation Accuracy: 77.3800\n",
      "[Epoch 46] Test Accuracy: 76.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.96batch/s, Data=0.049s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.3744, Loss_x=1.1550, Loss_u=0.0115, W=18.9987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47] (naive) Test Accuracy: 0.7694\n",
      "[Epoch 47] Train Accuracy: 84.5853\n",
      "[Epoch 47] Validation Accuracy: 77.4800\n",
      "[Epoch 47] Test Accuracy: 76.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.92batch/s, Data=0.047s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.3872, Loss_x=1.1621, Loss_u=0.0116, W=19.3987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48] (naive) Test Accuracy: 0.7782\n",
      "[Epoch 48] Train Accuracy: 84.5052\n",
      "[Epoch 48] Validation Accuracy: 77.7600\n",
      "[Epoch 48] Test Accuracy: 76.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 156/156 [00:11<00:00, 13.99batch/s, Data=0.046s, Batch=0.073s, Total=0:00:11, ETA=0:00:00, Loss=1.4107, Loss_x=1.1719, Loss_u=0.0121, W=19.7987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49] (naive) Test Accuracy: 0.7754\n",
      "[Epoch 49] Train Accuracy: 84.8858\n",
      "[Epoch 49] Validation Accuracy: 77.8600\n",
      "[Epoch 49] Test Accuracy: 77.1600\n",
      "Best acc:\n",
      "77.86\n",
      "Mean acc:\n",
      "74.203\n"
     ]
    }
   ],
   "source": [
    "title = 'noisy-cifar-10'\n",
    "\n",
    "logger = Logger(os.path.join(_out, 'log.txt'), title=title)\n",
    "logger.set_names(['Train Loss', 'Train Loss X', 'Train Loss U',  'Valid Loss', 'Valid Acc.', 'Test Loss', 'Test Acc.'])\n",
    "writer = SummaryWriter(_out)\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "step = 0\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(_epochs):\n",
    "\n",
    "    train_loss, train_loss_x, train_loss_u = train(labeled_trainloader, unlabeled_trainloader, model, optim, ema_optim, train_criterion, epoch, use_cuda)\n",
    "    _, train_acc = validate(labeled_trainloader, ema_model, criterion, epoch, use_cuda, mode='Train Stats')\n",
    "    val_loss, val_acc = validate(val_loader, ema_model, criterion, epoch, use_cuda, mode='Valid Stats')\n",
    "    test_loss, test_acc = validate(test_loader, ema_model, criterion, epoch, use_cuda, mode='Test Stats ')\n",
    "\n",
    "    sched.step()\n",
    "\n",
    "    _test_acc = get_acc(model, test_loader)\n",
    "    print(f\"[Epoch {epoch}] (naive) Test Accuracy: {_test_acc:.4f}\")\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"[Epoch {epoch}] Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"[Epoch {epoch}] Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    \n",
    "    step = _train_iteration * (epoch + 1)\n",
    "\n",
    "    writer.add_scalar('losses/train_loss', train_loss, step)\n",
    "    writer.add_scalar('losses/valid_loss', val_loss, step)\n",
    "    writer.add_scalar('losses/test_loss', test_loss, step)\n",
    "\n",
    "    writer.add_scalar('accuracy/train_acc', train_acc, step)\n",
    "    writer.add_scalar('accuracy/val_acc', val_acc, step)\n",
    "    writer.add_scalar('accuracy/test_acc', test_acc, step)\n",
    "\n",
    "    logger.append([train_loss, train_loss_x, train_loss_u, val_loss, val_acc, test_loss, test_acc])\n",
    "\n",
    "    best_acc = max(val_acc, best_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "logger.close()\n",
    "writer.close()\n",
    "\n",
    "print('Best acc:')\n",
    "print(best_acc)\n",
    "\n",
    "print('Mean acc:')\n",
    "print(np.mean(test_accs[-20:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb67fc-c769-44de-ae04-3e94b66ffbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
