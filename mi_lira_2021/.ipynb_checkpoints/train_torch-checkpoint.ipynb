{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6727352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 10:29:20.858212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-13 10:29:20.870418: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-13 10:29:20.874083: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-13 10:29:22.186091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Re-implementing train.py based on PyTorch\n",
    "# \n",
    "# link.\n",
    "# https://github.com/tensorflow/privacy/blob/master/research/mi_lira_2021/train.py\n",
    "#\n",
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# pylint: skip-file\n",
    "# pyformat: disable\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import shutil\n",
    "from typing import Callable\n",
    "import json\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jn\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf  # For data augmentation.\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import app, flags\n",
    "\n",
    "import objax\n",
    "from objax.jaxboard import SummaryWriter, Summary\n",
    "from objax.util import EasyDict\n",
    "from objax.zoo import convnet, wide_resnet\n",
    "\n",
    "from dataset import DataSet\n",
    "\n",
    "############################# from MODEL ZOO\n",
    "import torch\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler, random_split\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405fead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "#\n",
    "# a temporary class for handling attributes \n",
    "#### \n",
    "FLAGS_ = {\n",
    "    'arch': 'resnet50',\n",
    "    'dataset': 'imagenet',\n",
    "    'epochs': 20,\n",
    "    'logdir': 'exp/imagenet-1k',\n",
    "    'expid': 3,\n",
    "    'num_experiments': 16,\n",
    "    'save_steps': 5,\n",
    "    'lr': 0.1,\n",
    "    'weight_decay': 0.0005,\n",
    "    'batch': 256,\n",
    "    'seed': None,\n",
    "    'pkeep': 0.5,\n",
    "    'augment': 'weak',\n",
    "    'only_subset': None,\n",
    "    'dataset_size': 40000,\n",
    "    'eval_steps': 1,\n",
    "    'abort_after_epoch': None,\n",
    "    'patience': None,\n",
    "    'tunename': False\n",
    "}\n",
    "\n",
    "class Flags:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        \n",
    "FLAGS = Flags(**FLAGS_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45888945",
   "metadata": {},
   "source": [
    "# TODO \n",
    "\n",
    "- [ ] runner interface (FLAG, ...) \n",
    "- [ ] dataset load / pre-process\n",
    "- [ ] model definition\n",
    "- [ ] optimization (loss function)\n",
    "- [ ] training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283f54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x, shift: int, mirror=True):\n",
    "    \"\"\"\n",
    "    Augmentation function used in training the model.\n",
    "    \"\"\"\n",
    "    y = x['image']\n",
    "    if mirror:\n",
    "        y = tf.image.random_flip_left_right(y)\n",
    "    y = tf.pad(y, [[shift] * 2, [shift] * 2, [0] * 2], mode='REFLECT')\n",
    "    y = tf.image.random_crop(y, tf.shape(x['image']))\n",
    "    return dict(image=y, label=x['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebedc0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(seed):\n",
    "    \"\"\"\n",
    "    This is the function to generate subsets of the data for training models.\n",
    "\n",
    "    First, we get the training dataset either from the numpy cache\n",
    "    or otherwise we load it from tensorflow datasets.\n",
    "\n",
    "    Then, we compute the subset. This works in one of two ways.\n",
    "\n",
    "    1. If we have a seed, then we just randomly choose examples based on\n",
    "       a prng with that seed, keeping FLAGS.pkeep fraction of the data.\n",
    "\n",
    "    2. Otherwise, if we have an experiment ID, then we do something fancier.\n",
    "       If we run each experiment independently then even after a lot of trials\n",
    "       there will still probably be some examples that were always included\n",
    "       or always excluded. So instead, with experiment IDs, we guarantee that\n",
    "       after FLAGS.num_experiments are done, each example is seen exactly half\n",
    "       of the time in train, and half of the time not in train.\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    if os.path.exists(os.path.join(FLAGS.logdir, \"x_train.npy\")):\n",
    "        print(\"Loading dataset from local... \")\n",
    "\n",
    "        train_inputs = np.load(os.path.join(FLAGS.logdir, \"x_train.npy\"))\n",
    "        train_labels = np.load(os.path.join(FLAGS.logdir, \"y_train.npy\"))\n",
    "\n",
    "        test_inputs = np.load(os.path.join(FLAGS.logdir, \"x_test.npy\"))\n",
    "        test_labels = np.load(os.path.join(FLAGS.logdir, \"y_test.npy\"))\n",
    "        \n",
    "    else: \n",
    "        print(\"First time, creating dataset...\")\n",
    "\n",
    "        # TODO update to a relative ptah \n",
    "        DATA_DIR = '/serenity/scratch/psml/repo/psml/data/ILSVRC2012'\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        imagenet_data = datasets.ImageNet(root=DATA_DIR, split='val', transform=transform)\n",
    "        \n",
    "        TRAIN_TEST_RATIO = 0.8\n",
    "        dataset_size = len(imagenet_data)\n",
    "        train_size = int(TRAIN_TEST_RATIO * dataset_size)\n",
    "        validation_size = dataset_size - train_size\n",
    "\n",
    "        train_dataset, test_dataset = random_split(imagenet_data, [train_size, validation_size])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "        train_inputs_, train_labels_ = [], [] \n",
    "        test_inputs_, test_labels_ = [], []\n",
    "\n",
    "        for images_, labels_ in tqdm(train_loader, desc=\"Transforming Tensor to Ndarray (Train) ...\"): \n",
    "            train_inputs_.append(images_)\n",
    "            train_labels_.append(labels_)\n",
    "        \n",
    "        for images_, labels_ in tqdm(test_loader, desc=\"Transforming Tensor to Ndarray (Test) ...\"): \n",
    "            test_inputs_.append(images_)\n",
    "            test_labels_.append(labels_)\n",
    "\n",
    "        train_inputs, train_labels = np.concatenate(train_inputs_, axis=0), np.concatenate(train_labels_, axis=0)\n",
    "        test_inputs, test_labels = np.concatenate(test_inputs_, axis=0), np.concatenate(test_labels_, axis=0)\n",
    "                \n",
    "        train_inputs = tf.transpose(train_inputs, perm=[0, 2, 3, 1])\n",
    "        test_inputs = tf.transpose(test_inputs, perm=[0, 2, 3, 1])\n",
    "\n",
    "        print(\"Saving *train.npy...\")\n",
    "        np.save(os.path.join(FLAGS.logdir, \"x_train.npy\"), train_inputs)\n",
    "        np.save(os.path.join(FLAGS.logdir, \"y_train.npy\"), train_labels)\n",
    "\n",
    "        print(\"Saving *test.npy...\")\n",
    "        np.save(os.path.join(FLAGS.logdir, \"x_test.npy\"), test_inputs)\n",
    "        np.save(os.path.join(FLAGS.logdir, \"y_test.npy\"), test_labels)\n",
    "        \n",
    "##\n",
    "    nclass = np.max(train_labels)+1\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    if FLAGS.num_experiments is not None:\n",
    "        np.random.seed(0)\n",
    "        keep = np.random.uniform(0,1,size=(FLAGS.num_experiments, FLAGS.dataset_size))\n",
    "        order = keep.argsort(0)\n",
    "        keep = order < int(FLAGS.pkeep * FLAGS.num_experiments)\n",
    "        keep = np.array(keep[FLAGS.expid], dtype=bool)\n",
    "    else:\n",
    "        keep = np.random.uniform(0, 1, size=FLAGS.dataset_size) <= FLAGS.pkeep\n",
    "\n",
    "    if FLAGS.only_subset is not None:\n",
    "        keep[FLAGS.only_subset:] = 0\n",
    "    \n",
    "    xs = train_inputs[keep]\n",
    "    ys = train_labels[keep]\n",
    "    \n",
    "    if FLAGS.augment == 'weak':\n",
    "        aug = lambda x: augment(x, 4)\n",
    "    elif FLAGS.augment == 'mirror':\n",
    "        aug = lambda x: augment(x, 0)\n",
    "    elif FLAGS.augment == 'none':\n",
    "        aug = lambda x: augment(x, 0, mirror=False)\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "    train = DataSet.from_arrays(xs, ys, augment_fn=aug)\n",
    "    train = train.cache().shuffle(8192).repeat().parse().augment().batch(FLAGS.batch)\n",
    "    train = train.nchw().one_hot(nclass).prefetch(16)\n",
    "    \n",
    "    test = DataSet.from_arrays(test_inputs, test_labels)\n",
    "    test = test.cache().parse().batch(FLAGS.batch).nchw().prefetch(16)\n",
    "    \n",
    "    return train, test, xs, ys, keep, nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47f6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, device='cuda', lr=0.01, weight_decay=1e-4, logdir='logs'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9, weight_decay=self.weight_decay)\n",
    "        self.ema_model = ExponentialMovingAverage(model.parameters(), decay=0.999)\n",
    "#         self.ema_decay = 0.999\n",
    "        \n",
    "        self.writer = SummaryWriter(FLAGS.logdir)\n",
    "        \n",
    "        # TODO \n",
    "        # global parameter: num_epochs\n",
    "        \n",
    "        \n",
    "    def adjust_learning_rate(self, progress):\n",
    "        lr = self.initial_lr * torch.cos(progress * (7 * torch.pi) / (2 * 8))\n",
    "        lr = lr * torch.clamp(progress * 100, 0, 1)\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr.item()\n",
    "        return lr.item()\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs):\n",
    "        self.model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "#         number_of_training_examples // batch_size +1  .\n",
    "#         total_batches = self.dataset_size // FLAGS.batch + 1 \n",
    "        \n",
    "        for batch_idx, data in enumerate(self.train_loader):\n",
    "            images, labels = data['image'].to(self.device), data['label'].to(self.device)\n",
    "            progress = (batch_idx + epoch * FLAGS.dataset_size) / (num_epochs * FLAGS.dataset_size)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(images)\n",
    "            \n",
    "            loss_xe = F.cross_entropy(logits, labels)\n",
    "#             loss_wd = 0.5 * sum((p ** 2).sum() for p in self.model.parameters())\n",
    "#             loss = loss_xe + self.weight_decay * loss_wd\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # EMA update\n",
    "            self.ema_model.update()\n",
    "\n",
    "            running_loss += loss_xe.item()\n",
    "            if batch_idx % 100 == 99:  # log every 100 mini-batches\n",
    "                print(f'[Epoch {epoch+1}, Batch {batch_idx+1}] loss: {running_loss/100:.3f}')\n",
    "                self.writer.add_scalar('training loss', running_loss / 100, epoch * len(self.train_loader) + batch_idx)\n",
    "                running_loss = 0.0\n",
    "\n",
    "    def evaluate(self, epoch):\n",
    "        self.model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in self.test_loader:\n",
    "                images, labels = data['image'].to(self.device), data['label'].to(self.device)\n",
    "                logits = self.model(images)\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        self.writer.add_scalar('eval/accuracy', accuracy, epoch)\n",
    "        print(f'Accuracy of the model on test images: {accuracy:.2f}%')\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "    def save_checkpoint(self, epoch, best=False):\n",
    "        checkpoint_dir = 'checkpoints'\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n",
    "        if best:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "        torch.save(self.model.state_dict(), checkpoint_path)\n",
    "\n",
    "    def fit(self, num_epochs, patience=None, save_steps=1):\n",
    "        best_acc = 0.0\n",
    "        best_epoch = -1\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Train for one epoch\n",
    "            self.train_one_epoch(epoch, num_epochs)\n",
    "\n",
    "            # Evaluate the model\n",
    "            accuracy = self.evaluate(epoch)\n",
    "\n",
    "            # Save the best model\n",
    "            if accuracy > best_acc:\n",
    "                best_acc = accuracy\n",
    "                best_epoch = epoch\n",
    "                self.save_checkpoint(epoch, best=True)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Early stopping check\n",
    "            if patience is not None and patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "            # Save checkpoints periodically\n",
    "            if epoch % save_steps == save_steps - 1:\n",
    "                self.save_checkpoint(epoch)\n",
    "\n",
    "        print(f'Best Accuracy: {best_acc:.2f}% at epoch {best_epoch+1}')\n",
    "        self.writer.close()\n",
    "\n",
    "\n",
    "# Usage\n",
    "# Assuming `model`, `train_loader`, and `test_loader` are defined elsewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ac1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(arch: str):\n",
    "    # https://pytorch.org/vision/stable/models.html\n",
    "    TORCHVISION_MODELS = ['resnet18', 'resnet50', 'resnet101', 'vgg16', 'vgg19', 'densenet121', \n",
    "                          'wide_resnet50_2', 'wide_resnet101_2'\n",
    "                          'densenet201', 'mobilenet_v2', 'inception_v3', \n",
    "                          'efficientnet_b0', 'efficientnet_b7', \n",
    "                          'squeezenet1_0', 'alexnet', 'googlenet', 'shufflenet_v2_x1_0']\n",
    "    \n",
    "    # https://github.com/huggingface/pytorch-image-models\n",
    "    PYTORCH_IMAGE_MODELS = ['vit_base_patch16_224', 'vit_large_patch16_224', 'deit_base_patch16_224',\n",
    "                        'convnext_base', 'convnext_large']\n",
    "    \n",
    "    if arch in TORCHVISION_MODELS:\n",
    "        return models.__dict__[arch](pretrained=True)\n",
    "    elif arch in PYTORCH_IMAGE_MODELS:\n",
    "        return timm.create_model(arch, pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa16916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535273ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from local... \n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, xs, ys, keep, nclass = get_data(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b354083",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_PrefetchDataset' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "train_loader.data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69a452a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/scratch/debopam/env/envs/psml/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/coc/scratch/debopam/env/envs/psml/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "m = network('resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f96e5834",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'DataSet' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(m, train_loader, test_loader, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, logdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 89\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, num_epochs, patience, save_steps)\u001b[0m\n\u001b[1;32m     85\u001b[0m patience_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(epoch)\n",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[0;34m(self, epoch, num_epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     30\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 31\u001b[0m total_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m     34\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'DataSet' has no len()"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(m, train_loader, test_loader, lr=0.01, weight_decay=1e-4, logdir='logs')\n",
    "trainer.fit(num_epochs=20, patience=5, save_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37e42fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5656e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5efd0a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <tf.Tensor: shape=(256, 3, 224, 224), dtype=float32, numpy=\n",
       " array([[[[-0.4054286 , -0.57667613, -0.7650484 , ..., -0.67942464,\n",
       "           -0.69654936, -0.9362959 ],\n",
       "          [-0.5253019 , -0.5424266 , -0.55955136, ..., -0.81642264,\n",
       "           -0.9362959 , -0.69654936],\n",
       "          [-0.4054286 , -0.57667613, -0.7650484 , ..., -0.67942464,\n",
       "           -0.69654936, -0.9362959 ],\n",
       "          ...,\n",
       "          [-1.0561693 , -1.0219197 , -0.95342064, ..., -0.6451751 ,\n",
       "           -0.42255333, -0.25130582],\n",
       "          [-1.141793  , -1.004795  , -1.0219197 , ..., -0.7307989 ,\n",
       "           -0.6109256 , -0.59380084],\n",
       "          [-1.0561693 , -0.9020464 , -0.6280504 , ..., -0.79929787,\n",
       "           -1.0561693 , -1.0219197 ]],\n",
       " \n",
       "         [[-0.32002798, -0.565126  , -0.705182  , ..., -0.65266097,\n",
       "           -0.722689  , -0.862745  ],\n",
       "          [-0.565126  , -0.565126  , -0.495098  , ..., -0.792717  ,\n",
       "           -0.897759  , -0.65266097],\n",
       "          [-0.32002798, -0.565126  , -0.705182  , ..., -0.65266097,\n",
       "           -0.722689  , -0.862745  ],\n",
       "          ...,\n",
       "          [-1.0028011 , -1.107843  , -0.91526604, ..., -0.757703  ,\n",
       "           -0.47759098, -0.28501397],\n",
       "          [-1.0378151 , -0.9677871 , -0.9502801 , ..., -0.687675  ,\n",
       "           -0.635154  , -0.617647  ],\n",
       "          [-1.0378151 , -0.897759  , -0.740196  , ..., -0.77521   ,\n",
       "           -1.055322  , -0.93277305]],\n",
       " \n",
       "         [[-0.41010883, -0.54954237, -0.5669716 , ..., -0.514684  ,\n",
       "           -0.63668835, -0.74126357],\n",
       "          [-0.67154676, -0.7064052 , -0.60182995, ..., -0.5669716 ,\n",
       "           -0.7586928 , -0.5321132 ],\n",
       "          [-0.41010883, -0.54954237, -0.5669716 , ..., -0.514684  ,\n",
       "           -0.63668835, -0.74126357],\n",
       "          ...,\n",
       "          [-0.8981263 , -0.8981263 , -0.8109804 , ..., -0.5669716 ,\n",
       "           -0.37525046, -0.23581691],\n",
       "          [-0.86326796, -0.82840955, -0.86326796, ..., -0.6192592 ,\n",
       "           -0.5669716 , -0.5321132 ],\n",
       "          [-0.8109804 , -0.7586928 , -0.7064052 , ..., -0.68897593,\n",
       "           -0.82840955, -0.68897593]]],\n",
       " \n",
       " \n",
       "        [[[-0.57667613, -0.6280504 , -0.67942464, ...,  0.3651854 ,\n",
       "            0.43368444,  0.50218344],\n",
       "          [-0.7136741 , -0.7136741 , -0.67942464, ...,  0.34806067,\n",
       "            0.41655967,  0.4850587 ],\n",
       "          [-0.7479236 , -0.7136741 , -0.67942464, ...,  0.34806067,\n",
       "            0.38231018,  0.39943492],\n",
       "          ...,\n",
       "          [ 0.34806067,  0.33093593,  0.34806067, ..., -1.8267832 ,\n",
       "           -1.6897851 , -1.6726604 ],\n",
       "          [ 0.39943492,  0.2966864 ,  0.31381115, ..., -1.8267832 ,\n",
       "           -1.7240347 , -1.6555357 ],\n",
       "          [ 0.43368444,  0.24531215,  0.1939379 , ..., -1.7754089 ,\n",
       "           -1.7069099 , -1.6897851 ]],\n",
       " \n",
       "         [[-0.565126  , -0.635154  , -0.705182  , ...,  0.62535024,\n",
       "            0.69537824,  0.74789923],\n",
       "          [-0.705182  , -0.722689  , -0.687675  , ...,  0.6078432 ,\n",
       "            0.6603642 ,  0.69537824],\n",
       "          [-0.757703  , -0.722689  , -0.687675  , ...,  0.6078432 ,\n",
       "            0.62535024,  0.62535024],\n",
       "          ...,\n",
       "          [ 0.45028022,  0.41526622,  0.4677872 , ..., -1.8081232 ,\n",
       "           -1.6855742 , -1.6680672 ],\n",
       "          [ 0.50280124,  0.3802522 ,  0.4327732 , ..., -1.8081232 ,\n",
       "           -1.7205882 , -1.6505601 ],\n",
       "          [ 0.5378152 ,  0.3452382 ,  0.3102242 , ..., -1.7380952 ,\n",
       "           -1.7030813 , -1.6855742 ]],\n",
       " \n",
       "         [[-0.44496724, -0.54954237, -0.6192592 , ...,  1.0190852 ,\n",
       "            1.0888019 ,  1.1585187 ],\n",
       "          [-0.60182995, -0.63668835, -0.60182995, ...,  1.0016559 ,\n",
       "            1.0713727 ,  1.1236603 ],\n",
       "          [-0.63668835, -0.6192592 , -0.5844008 , ...,  1.0016559 ,\n",
       "            1.0190852 ,  1.0365143 ],\n",
       "          ...,\n",
       "          [ 0.6007845 ,  0.5484969 ,  0.6356429 , ..., -1.6127234 ,\n",
       "           -1.5081482 , -1.5081482 ],\n",
       "          [ 0.65307206,  0.51363856,  0.5833553 , ..., -1.6301525 ,\n",
       "           -1.5604358 , -1.490719  ],\n",
       "          [ 0.70535964,  0.47878015,  0.47878015, ..., -1.5778649 ,\n",
       "           -1.5430065 , -1.5255773 ]]],\n",
       " \n",
       " \n",
       "        [[[ 1.1015497 ,  1.0844251 ,  1.0673003 , ...,  0.50218344,\n",
       "            0.4850587 ,  0.5364329 ],\n",
       "          [ 1.1186745 ,  1.1015497 ,  1.0330508 , ...,  0.43368444,\n",
       "            0.50218344,  0.5535577 ],\n",
       "          [ 1.1015497 ,  1.1015497 ,  1.0673003 , ...,  0.46793392,\n",
       "            0.5193082 ,  0.57068247],\n",
       "          ...,\n",
       "          [-1.1246684 , -0.8677969 , -0.43967807, ..., -0.33692956,\n",
       "           -0.5081771 , -0.7479236 ],\n",
       "          [-1.1075436 , -0.88492167, -0.43967807, ..., -0.30268008,\n",
       "           -0.5253019 , -0.7479236 ],\n",
       "          [-1.141793  , -0.91917115, -0.45680285, ..., -0.25130582,\n",
       "           -0.4739276 , -0.7136741 ]],\n",
       " \n",
       "         [[ 1.2556022 ,  1.2556022 ,  1.2205883 , ...,  0.64285725,\n",
       "            0.62535024,  0.6778712 ],\n",
       "          [ 1.2380953 ,  1.2731093 ,  1.2205883 , ...,  0.5903362 ,\n",
       "            0.64285725,  0.69537824],\n",
       "          [ 1.2380953 ,  1.2205883 ,  1.2205883 , ...,  0.6078432 ,\n",
       "            0.6603642 ,  0.71288526],\n",
       "          ...,\n",
       "          [-1.247899  , -1.055322  , -0.757703  , ..., -0.32002798,\n",
       "           -0.547619  , -0.84523803],\n",
       "          [-1.247899  , -1.0903361 , -0.77521   , ..., -0.30252096,\n",
       "           -0.582633  , -0.84523803],\n",
       "          [-1.265406  , -1.12535   , -0.792717  , ..., -0.24999997,\n",
       "           -0.53011197, -0.827731  ]],\n",
       " \n",
       "         [[ 1.4373858 ,  1.4199566 ,  1.4373858 , ...,  0.8970808 ,\n",
       "            0.8447932 ,  0.91451   ],\n",
       "          [ 1.4722441 ,  1.4722441 ,  1.4025275 , ...,  0.827364  ,\n",
       "            0.8622224 ,  0.9319392 ],\n",
       "          [ 1.4373858 ,  1.454815  ,  1.454815  , ...,  0.827364  ,\n",
       "            0.8970808 ,  0.94936836],\n",
       "          ...,\n",
       "          [-1.6301525 , -1.403573  , -1.0724182 , ..., -0.6192592 ,\n",
       "           -0.86326796, -1.1421349 ],\n",
       "          [-1.6301525 , -1.4384314 , -1.0724182 , ..., -0.5844008 ,\n",
       "           -0.86326796, -1.1247058 ],\n",
       "          [-1.6301525 , -1.4732897 , -1.0898474 , ..., -0.5321132 ,\n",
       "           -0.79355115, -1.0724182 ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 1.3241715 ,  1.2727973 ,  1.1529241 , ...,  1.0673003 ,\n",
       "            0.9816765 ,  1.1186745 ],\n",
       "          [ 1.5125438 ,  1.3584211 ,  1.1357993 , ...,  1.0501755 ,\n",
       "            1.015926  ,  1.0330508 ],\n",
       "          [ 1.3584211 ,  1.1871736 ,  1.015926  , ...,  1.1357993 ,\n",
       "            1.1357993 ,  1.0673003 ],\n",
       "          ...,\n",
       "          [ 2.0262864 ,  2.11191   ,  2.1632845 , ...,  1.6837914 ,\n",
       "            1.4440448 ,  0.878928  ],\n",
       "          [ 2.1461596 ,  2.1804092 ,  2.11191   , ...,  1.7694151 ,\n",
       "            1.7351656 ,  1.5810429 ],\n",
       "          [ 2.0947855 ,  2.1632845 ,  2.0776608 , ...,  1.8379141 ,\n",
       "            1.5981677 ,  1.221423  ]],\n",
       " \n",
       "         [[ 1.4831933 ,  1.3781513 ,  1.2030813 , ...,  1.0630252 ,\n",
       "            1.0105042 ,  1.1505603 ],\n",
       "          [ 1.5882353 ,  1.3956583 ,  1.1680672 , ...,  1.0630252 ,\n",
       "            0.9929972 ,  1.0455183 ],\n",
       "          [ 1.3431373 ,  1.1855743 ,  1.0455183 , ...,  1.1155462 ,\n",
       "            1.0980393 ,  1.0630252 ],\n",
       "          ...,\n",
       "          [ 2.0959384 ,  2.1134453 ,  1.9908963 , ...,  1.4656863 ,\n",
       "            1.2731093 ,  0.71288526],\n",
       "          [ 1.9733893 ,  2.0784314 ,  1.9383754 , ...,  1.5882353 ,\n",
       "            1.6057423 ,  1.4831933 ],\n",
       "          [ 1.7633053 ,  1.9558823 ,  1.9208683 , ...,  1.7282913 ,\n",
       "            1.1680672 ,  0.87044823]],\n",
       " \n",
       "         [[ 1.454815  ,  1.3328106 ,  1.1410894 , ...,  1.0713727 ,\n",
       "            1.0016559 ,  1.1062311 ],\n",
       "          [ 1.5942485 ,  1.367669  ,  1.0888019 , ...,  1.0713727 ,\n",
       "            1.0190852 ,  0.98422676],\n",
       "          [ 1.3153814 ,  1.0888019 ,  0.9319392 , ...,  1.1410894 ,\n",
       "            1.1236603 ,  0.98422676],\n",
       "          ...,\n",
       "          [ 2.0648367 ,  2.0822659 ,  1.8208281 , ...,  1.2630938 ,\n",
       "            1.1062311 ,  0.5484969 ],\n",
       "          [ 1.733682  ,  1.9602616 ,  1.6639653 , ...,  1.4199566 ,\n",
       "            1.454815  ,  1.3502399 ],\n",
       "          [ 1.454815  ,  1.6639653 ,  1.5245317 , ...,  1.6116778 ,\n",
       "            0.9319392 ,  0.6182137 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.42255333, -0.2170563 , -0.23418105, ..., -0.13143253,\n",
       "           -1.2616663 , -1.2616663 ],\n",
       "          [-0.57667613, -0.43967807, -0.31980482, ..., -0.30268008,\n",
       "           -1.4500387 , -1.5870366 ],\n",
       "          [-0.30268008, -0.30268008, -0.2855553 , ...,  1.0501755 ,\n",
       "            0.50218344,  0.10831413],\n",
       "          ...,\n",
       "          [ 2.0776608 ,  2.0776608 ,  2.060536  , ..., -1.1760426 ,\n",
       "           -1.3301654 , -1.4671633 ],\n",
       "          [ 1.5639181 ,  1.4440448 ,  1.3241715 , ..., -1.073294  ,\n",
       "           -1.2102921 , -1.4329139 ],\n",
       "          [ 0.7590547 ,  0.69055575,  0.6563062 , ..., -1.0219197 ,\n",
       "           -1.004795  , -1.1760426 ]],\n",
       " \n",
       "         [[-0.670168  , -0.60014   , -0.65266097, ..., -0.03991595,\n",
       "           -1.212885  , -1.1953781 ],\n",
       "          [-0.792717  , -0.705182  , -0.635154  , ..., -0.33753496,\n",
       "           -1.457983  , -1.5455182 ],\n",
       "          [-0.617647  , -0.65266097, -0.635154  , ...,  0.8004202 ,\n",
       "            0.04761905, -0.28501397],\n",
       "          ...,\n",
       "          [ 2.1134453 ,  1.9733893 ,  1.8508403 , ..., -1.1953781 ,\n",
       "           -1.317927  , -1.3879551 ],\n",
       "          [ 1.3081232 ,  1.1855743 ,  1.1155462 , ..., -1.107843  ,\n",
       "           -1.212885  , -1.3879551 ],\n",
       "          [ 0.64285725,  0.64285725,  0.62535024, ..., -1.0378151 ,\n",
       "           -1.0378151 , -1.160364  ]],\n",
       " \n",
       "         [[-0.41010883, -0.35782126, -0.41010883, ...,  0.2522005 ,\n",
       "           -0.8458387 , -0.8981263 ],\n",
       "          [-0.47982562, -0.44496724, -0.41010883, ...,  0.06047938,\n",
       "           -1.0027015 , -1.1247058 ],\n",
       "          [-0.28810447, -0.2706753 , -0.30553368, ...,  0.8099348 ,\n",
       "            0.23477131, -0.0092374 ],\n",
       "          ...,\n",
       "          [ 2.3262744 ,  2.2565577 ,  2.1345534 , ..., -1.0375599 ,\n",
       "           -1.1421349 , -1.2467101 ],\n",
       "          [ 1.6639653 ,  1.6116778 ,  1.4896734 , ..., -0.9329847 ,\n",
       "           -1.0549891 , -1.2467101 ],\n",
       "          [ 1.1236603 ,  1.1410894 ,  1.1062311 , ..., -0.91555554,\n",
       "           -0.86326796, -1.0027015 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.5364329 ,  0.45080918,  0.46793392, ...,  0.5364329 ,\n",
       "            0.5878072 ,  0.60493195],\n",
       "          [ 0.43368444,  0.39943492,  0.43368444, ...,  0.63918144,\n",
       "            0.6220567 ,  0.6220567 ],\n",
       "          [ 0.39943492,  0.39943492,  0.41655967, ...,  0.72480524,\n",
       "            0.70768046,  0.673431  ],\n",
       "          ...,\n",
       "          [ 0.45080918,  0.4850587 ,  0.45080918, ...,  0.43368444,\n",
       "            0.5193082 ,  0.4850587 ],\n",
       "          [ 0.24531215,  0.2966864 ,  0.31381115, ...,  0.5364329 ,\n",
       "            0.5364329 ,  0.50218344],\n",
       "          [ 0.12543888,  0.10831413,  0.14256364, ...,  0.5535577 ,\n",
       "            0.5364329 ,  0.57068247]],\n",
       " \n",
       "         [[ 0.6603642 ,  0.57282925,  0.5903362 , ...,  0.6778712 ,\n",
       "            0.7303922 ,  0.7303922 ],\n",
       "          [ 0.55532223,  0.5203082 ,  0.55532223, ...,  0.78291327,\n",
       "            0.76540625,  0.74789923],\n",
       "          [ 0.5203082 ,  0.5203082 ,  0.5378152 , ...,  0.8529412 ,\n",
       "            0.83543426,  0.8004202 ],\n",
       "          ...,\n",
       "          [ 0.5378152 ,  0.5903362 ,  0.55532223, ...,  0.55532223,\n",
       "            0.64285725,  0.6078432 ],\n",
       "          [ 0.3277312 ,  0.3977592 ,  0.41526622, ...,  0.6603642 ,\n",
       "            0.6603642 ,  0.62535024],\n",
       "          [ 0.18767506,  0.2051822 ,  0.2401962 , ...,  0.6778712 ,\n",
       "            0.6603642 ,  0.6778712 ]],\n",
       " \n",
       "         [[ 0.9667976 ,  0.8796516 ,  0.8970808 , ...,  0.9319392 ,\n",
       "            1.0016559 ,  1.0365143 ],\n",
       "          [ 0.8622224 ,  0.827364  ,  0.8622224 , ...,  1.0365143 ,\n",
       "            1.0365143 ,  1.0539435 ],\n",
       "          [ 0.827364  ,  0.827364  ,  0.8447932 , ...,  1.1410894 ,\n",
       "            1.1410894 ,  1.1062311 ],\n",
       "          ...,\n",
       "          [ 0.8447932 ,  0.8970808 ,  0.8622224 , ...,  0.8622224 ,\n",
       "            0.94936836,  0.91451   ],\n",
       "          [ 0.6356429 ,  0.70535964,  0.7227889 , ...,  0.9667976 ,\n",
       "            0.9667976 ,  0.9319392 ],\n",
       "          [ 0.51363856,  0.51363856,  0.5484969 , ...,  0.98422676,\n",
       "            0.9667976 ,  0.98422676]]]], dtype=float32)>,\n",
       " 'label': <tf.Tensor: shape=(256, 1000), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = iterator.get_next()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa4c217",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The dataset is infinite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/scratch/debopam/env/envs/psml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:531\u001b[0m, in \u001b[0;36mDatasetV2.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcardinality()\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m==\u001b[39m INFINITE:\n\u001b[0;32m--> 531\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset is infinite.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m==\u001b[39m UNKNOWN:\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset length is unknown.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: The dataset is infinite."
     ]
    }
   ],
   "source": [
    "len(train_loader.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43ec2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = m(torch.from_numpy(images.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d125ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbbcd833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19917"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d428fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4196e+00, -1.2758e+00, -3.9712e+00,  ..., -1.0529e+00,\n",
       "         -1.3773e+00,  6.4069e+00],\n",
       "        [-2.1180e+00, -2.7036e-01, -5.4485e-03,  ..., -5.5878e-01,\n",
       "          9.9498e-02, -4.4625e-01],\n",
       "        [ 2.7040e+00, -8.7923e-01, -6.9519e-01,  ...,  1.2780e+00,\n",
       "          2.2677e-01, -6.8925e-01],\n",
       "        ...,\n",
       "        [-5.6048e-01,  9.8632e-01,  5.2000e+00,  ..., -1.7108e+00,\n",
       "          2.4272e+00,  1.3268e+00],\n",
       "        [-2.5208e+00, -3.2628e+00,  1.6351e+00,  ...,  9.9490e-01,\n",
       "          3.1441e+00,  7.1338e-01],\n",
       "        [ 5.2069e-01, -5.4838e+00, -2.8739e+00,  ..., -1.2691e+00,\n",
       "          2.9342e+00,  2.0972e+00]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "92a3095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([256, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(type(logits))\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42ab7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, xs, ys, keep, nclass = get_data(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb85f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02fdc792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/scratch/debopam/env/envs/psml/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/coc/scratch/debopam/env/envs/psml/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "m = network('resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0857ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.models.resnet.ResNet"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b694ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    flags.DEFINE_float('lr', 0.1, 'Learning rate.')\n",
    "    flags.DEFINE_float('weight_decay', 0.0005, 'Weight decay ratio.')\n",
    "    flags.DEFINE_integer('batch', 256, 'Batch size')\n",
    "    flags.DEFINE_integer('seed', None, 'Training seed.')\n",
    "    flags.DEFINE_float('pkeep', .5, 'Probability to keep examples.')\n",
    "    flags.DEFINE_string('augment', 'weak', 'Strong or weak augmentation')\n",
    "    flags.DEFINE_integer('only_subset', None, 'Only train on a subset of images.')\n",
    "    flags.DEFINE_integer('dataset_size', 50000, 'number of examples to keep.')\n",
    "    flags.DEFINE_integer('eval_steps', 1, 'how often to get eval accuracy.')\n",
    "    flags.DEFINE_integer('abort_after_epoch', None, 'stop trainin early at an epoch')\n",
    "    flags.DEFINE_integer('patience', None, 'Early stopping after this many epochs without progress')\n",
    "    flags.DEFINE_bool('tunename', False, 'Use tune name?')\n",
    "\n",
    "    ### override \n",
    "    # https://github.com/tensorflow/privacy/tree/d965556ebb67bd62626830339478e9ebab7ab9bd/research/mi_lira_2021/scripts  \n",
    "    #     CUDA_VISIBLE_DEVICES='0' python3 -u train.py --dataset=cifar10 --epochs=100 --save_steps=20 --arch wrn28-2 --num_experiments 16 --expid 0 --logdir exp/cifar10 &> logs/log_0\n",
    "\n",
    "    flags.DEFINE_string('dataset', 'cifar10', 'Dataset.')\n",
    "    flags.DEFINE_string('arch', 'wrn28-2', 'Model architecture.')\n",
    "\n",
    "    flags.DEFINE_integer('epochs', 20, 'Training duration in number of epochs.')\n",
    "    flags.DEFINE_integer('save_steps', 5, 'how often to get save model.')\n",
    "    flags.DEFINE_integer('num_experiments', 16, 'Number of experiments')\n",
    "    flags.DEFINE_integer('expid', 3, 'Experiment ID')\n",
    "    flags.DEFINE_string('logdir', 'experiments', 'Directory where to save checkpoints and tensorboard data.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
